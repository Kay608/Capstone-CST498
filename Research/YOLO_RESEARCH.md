# YOLO Sign Detection Research & Implementation Plan

## Overview

YOLO (You Only Look Once) is a real-time object detection system that will enable your delivery robot to detect and respond to campus signs, traffic signals, and navigation markers.

## Why YOLO for This Project?

âœ… **Real-time Performance**: Processes images in a single pass (~30+ FPS)  
âœ… **Raspberry Pi Compatible**: Optimized models available for edge devices  
âœ… **Pre-trained Models**: Already trained on common objects including signs  
âœ… **Custom Training**: Can train on campus-specific signs  
âœ… **Active Community**: Excellent documentation and support  

## Implementation Strategy

### Phase 1: Basic YOLO Integration (September)

1. **Install and Test YOLO**
   ```bash
   pip install ultralytics
   ```

2. **Test with Pre-trained Model**
   - Use YOLOv8n (nano) for Raspberry Pi
   - Test detection on common objects
   - Measure performance on Pi 5

3. **Camera Integration**
   - Integrate with existing camera system
   - Real-time sign detection
   - Basic classification (stop, yield, directional signs)

### Phase 2: Custom Training (October)

1. **Dataset Creation**
   - Photograph campus signs from multiple angles
   - Include various lighting conditions
   - Annotate using tools like Roboflow or LabelImg

2. **Training Pipeline**
   - Fine-tune YOLOv8 on campus signs
   - Validate on test set
   - Optimize for Raspberry Pi deployment

3. **Sign Categories for Campus**
   - **Navigation Signs**: Building names, directions
   - **Traffic Signs**: Stop, yield, speed limits
   - **Delivery Zones**: Pickup/dropoff areas
   - **Restricted Areas**: No entry, staff only

### Phase 3: Navigation Integration (November)

1. **Sign-Based Navigation Rules**
   - Stop at stop signs (3-second pause)
   - Reduce speed in restricted zones
   - Navigate to delivery zones
   - Avoid restricted areas

2. **Decision Making System**
   - Priority system for conflicting signs
   - Distance-based sign relevance
   - Integration with pathfinding

## Technical Implementation

### YOLO Integration Architecture

```python
# yolo_detector.py (to be created)
class YOLOSignDetector:
    def __init__(self, model_path="yolov8n.pt"):
        self.model = YOLO(model_path)
        self.sign_classes = {
            'stop_sign': 0,
            'yield_sign': 1,
            'speed_limit': 2,
            'building_sign': 3,
            'delivery_zone': 4
        }
    
    def detect_signs(self, image):
        results = self.model(image)
        return self.process_detections(results)
    
    def process_detections(self, results):
        signs = []
        for result in results:
            for box in result.boxes:
                sign_info = {
                    'class': self.sign_classes[box.cls],
                    'confidence': box.conf,
                    'bbox': box.xyxy,
                    'distance': self.estimate_distance(box)
                }
                signs.append(sign_info)
        return signs
```

### Navigation Rule Engine

```python
# sign_navigation.py (to be created)
class SignNavigationEngine:
    def __init__(self, robot_controller):
        self.controller = robot_controller
        self.sign_rules = {
            'stop_sign': self.handle_stop_sign,
            'yield_sign': self.handle_yield_sign,
            'speed_limit': self.handle_speed_limit,
            'delivery_zone': self.handle_delivery_zone
        }
    
    def process_detected_signs(self, signs):
        for sign in signs:
            if sign['confidence'] > 0.7:  # Confidence threshold
                rule_handler = self.sign_rules.get(sign['class'])
                if rule_handler:
                    rule_handler(sign)
    
    def handle_stop_sign(self, sign):
        if sign['distance'] < 2.0:  # 2 meters
            self.controller.stop()
            time.sleep(3)  # Stop for 3 seconds
            
    def handle_delivery_zone(self, sign):
        if sign['distance'] < 5.0:  # 5 meters
            self.controller.set_delivery_mode(True)
```

## Dataset Requirements

### Campus Sign Categories

1. **Building/Location Signs**
   - Student Union, Library, Dining Hall
   - Department buildings (Engineering, Science, etc.)
   - Dormitories and residential areas

2. **Navigation Signs**
   - Directional arrows
   - Distance markers
   - Campus maps and kiosks

3. **Traffic Control**
   - Stop signs at intersections
   - Yield signs at crosswalks
   - Speed limit signs

4. **Service Areas**
   - Food delivery zones
   - Parking areas
   - Loading docks

### Data Collection Plan

**Target**: 500-1000 images per sign category

**Collection Strategy**:
- Different times of day (morning, afternoon, evening)
- Various weather conditions (sunny, cloudy, rainy)
- Multiple angles and distances
- Different seasons (if time permits)

**Annotation Tools**:
- **Roboflow**: Web-based, team collaboration
- **LabelImg**: Desktop application, simple to use
- **CVAT**: Advanced features, better for large datasets

## Performance Optimization

### Raspberry Pi 5 Optimization

1. **Model Selection**
   - YOLOv8n (nano): Fastest, good for real-time
   - YOLOv8s (small): Better accuracy, slightly slower
   - Custom quantized models for maximum speed

2. **Hardware Acceleration**
   - Use GPU acceleration if available
   - Optimize OpenCV for ARM architecture
   - Consider TensorRT or ONNX optimization

3. **Processing Optimization**
   - Process every 3rd frame instead of every frame
   - Use lower resolution for detection (640x480)
   - Implement region of interest (ROI) processing

### Real-time Processing Pipeline

```python
class OptimizedSignDetection:
    def __init__(self):
        self.frame_skip = 3  # Process every 3rd frame
        self.frame_count = 0
        self.last_detections = []
        
    def process_frame(self, frame):
        self.frame_count += 1
        
        if self.frame_count % self.frame_skip == 0:
            # Resize for faster processing
            small_frame = cv2.resize(frame, (640, 480))
            detections = self.yolo_detector.detect(small_frame)
            self.last_detections = detections
            
        return self.last_detections
```

## Testing Strategy

### Unit Testing
- Individual sign detection accuracy
- Distance estimation accuracy
- Processing speed benchmarks

### Integration Testing
- Sign detection during navigation
- Rule engine response times
- End-to-end campus navigation

### Campus Testing Plan

**Phase 1**: Controlled environment (single signs)
**Phase 2**: Simple routes (2-3 signs)
**Phase 3**: Complex campus navigation
**Phase 4**: Delivery scenarios with multiple decision points

## Risk Mitigation

### Technical Risks
- **Low accuracy**: Use ensemble methods, multiple models
- **Slow processing**: Optimize model, reduce resolution
- **False positives**: Implement confidence thresholds and filtering

### Environmental Risks
- **Weather conditions**: Train on diverse weather data
- **Lighting changes**: Use data augmentation techniques
- **Occlusion**: Implement temporal consistency checks

### Fallback Strategies
- **GPS navigation**: If sign detection fails
- **Manual override**: Remote control capability
- **Safe mode**: Stop and wait for assistance

## Timeline & Milestones

### September 2024
- [ ] Install YOLO and test basic detection
- [ ] Integrate with camera system
- [ ] Create initial sign detection module

### October 2024
- [ ] Collect and annotate campus sign dataset
- [ ] Train custom YOLO model
- [ ] Implement navigation rule engine
- [ ] Test individual sign responses

### November 2024
- [ ] Full system integration
- [ ] Campus testing and validation
- [ ] Performance optimization
- [ ] Demo preparation

## Resources & Learning Materials

### Documentation
- [Ultralytics YOLO Documentation](https://docs.ultralytics.com/)
- [YOLOv8 Training Guide](https://docs.ultralytics.com/modes/train/)
- [Custom Dataset Tutorial](https://docs.ultralytics.com/datasets/)

### Tools
- [Roboflow](https://roboflow.com/) - Dataset management and annotation
- [Weights & Biases](https://wandb.ai/) - Experiment tracking
- [TensorBoard](https://www.tensorflow.org/tensorboard) - Training visualization

### Example Datasets
- [Road Sign Detection Dataset](https://www.kaggle.com/datasets/andrewmvd/road-sign-detection)
- [Traffic Signs Dataset](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)

---

**Next Action Items**:
1. Install Ultralytics YOLO: `pip install ultralytics`
2. Test basic object detection on sample images
3. Plan campus sign photography session
4. Research annotation tools and select one for the team

**Estimated Development Time**: 6-8 weeks  
**Team Member Assignment**: Recommend assigning this to the team member most interested in computer vision

---

**Last Updated**: August 28, 2024  
**Status**: Research Complete, Ready for Implementation ðŸ“‹
